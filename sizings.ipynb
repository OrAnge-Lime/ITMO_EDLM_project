{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from cartoon_gan_origin.models.generator import Generator  \n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def benchmark_model(model, device, batch_sizes, image_size, warmup = 0, iters = 50):\n",
    "    results = []\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    for batch_size in batch_sizes:\n",
    "        dummy_input = torch.randn(batch_size, 3, image_size[0], image_size[1], device=device)\n",
    "\n",
    "        # WARMUP for compile\n",
    "        for _ in range(warmup):\n",
    "            _ = model(dummy_input)\n",
    "\n",
    "        # TIMING\n",
    "        times = []\n",
    "        for _ in tqdm(range(iters)):\n",
    "            start = time.time()\n",
    "            _ = model(dummy_input)\n",
    "            times.append(time.time() - start)\n",
    "\n",
    "        avg_time = sum(times) / len(times)\n",
    "        throughput = batch_size / avg_time\n",
    "        results.append({\n",
    "            \"device\": device.type,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"avg_time_sec\": avg_time,\n",
    "            \"throughput_fps\": throughput,\n",
    "        })\n",
    "        print(f\"{device.type} batch={batch_size} avg_time={avg_time*1000}ms throughput={throughput}img/s\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = [1, 4, 8, 16, 32, 64]\n",
    "IMG_SIZE = (128, 128)\n",
    "\n",
    "WEIGHTS = 'cartoon_gan_origin/checkpoints/trained_netG.pth'\n",
    "model_orig = Generator()\n",
    "model_orig.load_state_dict(torch.load(WEIGHTS, map_location='cpu'))\n",
    "\n",
    "WEIGHTS1 = 'cartoon_gan_origin/checkpoints/prun_distilation_G.pth'\n",
    "model1 = torch.load(WEIGHTS1, map_location='cpu', weights_only=False)\n",
    "\n",
    "WEIGHTS2 = 'cartoon_gan_origin/checkpoints/prun_distilation_G.pth'\n",
    "model2 = torch.load(WEIGHTS2, map_location='cpu', weights_only=False)\n",
    "\n",
    "WEIGHTS3 = 'cartoon_gan_origin/checkpoints/tune_trained_netG_20prun.pth'\n",
    "model3 = torch.load(WEIGHTS3, map_location='cpu', weights_only=False)\n",
    "\n",
    "cpu_stats, gpu_stats = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([n.numel() for n in model_orig.parameters()]), sum([n.numel() for n in model1.parameters()]), sum([n.numel() for n in model2.parameters()]), sum([n.numel() for n in model3.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU TEST\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "cpu_stats_orig = benchmark_model(model_orig, cpu_device, BATCH_SIZE, IMG_SIZE, iters=50)\n",
    "cpu_stats1 = benchmark_model(model1, cpu_device, BATCH_SIZE, IMG_SIZE, iters=50)\n",
    "cpu_stats2 = benchmark_model(model2, cpu_device, BATCH_SIZE, IMG_SIZE, iters=50)\n",
    "print('cpu test finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_stats3 = benchmark_model(model3, cpu_device, BATCH_SIZE, IMG_SIZE, iters=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(f'CPU Intel i5-12600KF CartoonGAN img{IMG_SIZE}')\n",
    "\n",
    "plt.plot(BATCH_SIZE, [d[\"throughput_fps\"] for d in cpu_stats_orig], marker=\"o\", label='orig_model')\n",
    "plt.plot(BATCH_SIZE, [d[\"throughput_fps\"] for d in cpu_stats1], marker=\"o\", label='prune10_model')\n",
    "plt.plot(BATCH_SIZE, [d[\"throughput_fps\"] for d in cpu_stats2], marker=\"o\", label='prune20_model')\n",
    "# plt.plot(BATCH_SIZE, [d[\"throughput_fps\"] for d in cpu_stats3], marker=\"o\", label='prune30_model')\n",
    "plt.grid(linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "plt.xlabel('Batch size')\n",
    "plt.ylabel('FPS images/s')\n",
    "plt.legend()\n",
    "plt.savefig(f'test_results/{IMG_SIZE}_cpu.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats = cpu_stats + gpu_stats\n",
    "\n",
    "with open(f\"test_results/benchmark_results_{tag}.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"device\", \"batch_size\", \"avg_time_sec\", \"throughput_fps\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(all_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
